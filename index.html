<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">

  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155581705-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-155581705-1');
  </script>


  <title>Martin Klissarov</title>
  
  <meta name="author" content="Martin Klissarov">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/mk_pixel.jpg">
</head>

<body>

  
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Martin Klissarov</name>
              </p>
              <p>I am a PhD student supervised by <a href="https://cs.mcgill.ca/">Prof. Doina Precup</a> at              <a href="https://cs.mcgill.ca/">McGill University</a>  and <a href="https://mila.quebec/">Mila</a>. I am particularly interested in <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">scalable</a> <a href="http://incompleteideas.net/IncIdeas/ConditionalPredictions.html">human-inspired</a> approaches to intelligence. 
              </p>
              <p>
                Humans are able to learn new skills and adapt to changes in a sample efficiency way, can RL agents do the same? My recent research is currently centered on meta reinforcement learning, together with temporal abstractions and off-policy methods, as a way to answer this question.
              </p>
              <p style="text-align:center">
                <a href="mailto:martin.klissarov@mail.mcgill.ca">Email</a> &nbsp|&nbsp
                <a href="https://scholar.google.ca/citations?user=nV-tcHAAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
                <a href="https://ca.linkedin.com/in/martin-klissarov-0b8b2b83"> LinkedIn </a>
                &nbsp|&nbsp
                <a href="https://twitter.com/mklissar"> Twitter </a> &nbsp|&nbsp
                <a href="./data/MartinKlissarov_resume.pdf"> CV </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/bali.png"><img style="width:100%;max-width:100%;border-radius:15px" alt="profile photo" src="images/bali_face.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>





        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
 

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" cellspacing="0" cellpadding="10">



          <tr>
            <td width="33%" valign="center" align="center"><a href="https://mklissa.github.io/"><img src="images/flexibleoption.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://mklissa.github.io/" id="flexibleoption">
              <heading>Flexible Option Learning</heading></a><br>
              <b>Martin Klissarov</b> and Doina Precup<br>
              Neural Information Processing Systems (NeurIPS), 2021, <font style="color:#ff5733">Spotlight</font>
              </p>
            


            <div class="paper" id="flexibleoption">
              pdf & code coming soon
            <!-- <a href="https://sites.google.com/view/optionsofinterest">webpage</a> | -->
            <!-- <a href="https://arxiv.org/abs/2010.02474">pdf</a>  -->
            <!-- | <a href="./data/phi_gcn.bib">bibtex</a>  -->
            <!-- | <a href="https://github.com/mklissa/phi_gcn">code</a> -->

            </div>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2010.02474"><img src="images/samplegraph.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://proceedings.neurips.cc/paper/2020/file/970627414218ccff3497cb7a784288f5-Paper.pdf" id="phi_gcn">
              <heading>Reward Propagation using Graph Convolutional Networks</heading></a><br>
              <b>Martin Klissarov</b> and Doina Precup<br>
              Neural Information Processing Systems (NeurIPS), 2020, <font style="color:#ff5733">Spotlight</font>
              </p>
            


            <div class="paper" id="phi_gcn">
            <!-- <a href="https://sites.google.com/view/optionsofinterest">webpage</a> | -->
            <a href="https://arxiv.org/abs/2010.02474">pdf</a> 
            | <a href="./data/phi_gcn.bib">bibtex</a> 
            | <a href="https://github.com/mklissa/phi_gcn">code</a>

            </div>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://128.84.21.199/pdf/2001.00271.pdf"><img src="images/opint.png" alt="sym" width="80%" height="150" style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://128.84.21.199/pdf/2001.00271.pdf" id="interest options">
              <heading>Options of Interest: Temporal Abstraction with Interest Functions</heading></a><br>
              Khimya Khetarpal, <b>Martin Klissarov</b>, Maxime Chevalier-Boisvert, Pierre-Luc Bacon, Doina Precup<br>
              Association for the Advancement of Artificial Intelligence (AAAI), 2020
              </p>
            


            <div class="paper" id="optionsofinterest">
            <a href="https://sites.google.com/view/optionsofinterest">webpage</a> |
            <a href="https://128.84.21.199/pdf/2001.00271.pdf">pdf</a> |
            <a href="./data/opint.bib">bibtex</a> |
            <a href="https://github.com/kkhetarpal/ioc">code</a>

            </div>
            </td>
          </tr>
 


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://tarl2019.github.io/assets/papers/klissarov2019variational.pdf"><img src="images/vse.png" alt="sym" width="80%"  style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://tarl2019.github.io/assets/papers/klissarov2019variational.pdf" id="interest options">
              <heading>Variational State Encoding<br/> </heading></a><br>
              <b>Martin Klissarov*</b>, Riashat Islam*, Khimya Khetarpal, Doina Precup<br>
              The Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM), 2019
              </p>


            <div class="paper" id="neurips19">



            <a href="https://tarl2019.github.io/assets/papers/klissarov2019variational.pdf">pdf</a> |
                          <a href="./data/vse.bib">bibtex</a> 


            </div>
            </td>
          </tr>




          <tr>
            <td width="33%" valign="center" align="center"><a href="https://openreview.net/forum?id=BkgkoToZZ7"><img src="images/graph.png" alt="sym" width="80%" style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://openreview.net/forum?id=BkgkoToZZ7" id="interest options">
              <heading>Diffusion-Based Approximate Value Functions<br/> </heading></a><br>
              <b>Martin Klissarov</b>, Doina Precup<br>
              International Conference on Machine Learning (ICML) Efficient Credit Assignemnt Workshop, 2018, <font style="color:#ff5733">Oral</font>
              </p>


            <div class="paper" id="neurips19">
            <a href="https://openreview.net/forum?id=BkgkoToZZ7">pdf</a>  |
            <a href="./data/davf.bib">bibtex</a> 

            </div>
            </td>
          </tr>





          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/1709.04571.pdf"><img src="images/amidar_db2.png" alt="sym" width="80%" height="150" style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/1709.04571.pdf" id="interest options">
              <heading>When Waiting is not an Option:  Learning Options using the Deliberation Cost<br/> </heading></a><br>
              Jean Harb, Pierre-Luc Bacon, <b>Martin Klissarov</b>,  Doina Precup<br>
              Association for the Advancement of Artificial Intelligence (AAAI), 2018
              </p>


            <div class="paper" id="a2oc">

            <a href="https://arxiv.org/pdf/1709.04571.pdf">pdf</a> |
            <a href="./data/option_db.bib">bibtex</a> |
            <a href="https://github.com/jeanharb/a2oc_delib">code</a>

            </div>
            </td>
          </tr>




          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/1712.00004.pdf"><img src="images/ppoc.gif" alt="sym" width="80%" style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/1712.00004.pdf" id="interest options">
              <heading>Learning Options End-to-End for Continuous Action Tasks<br/> </heading></a><br>
              <b>Martin Klissarov</b>, Pierre-Luc Bacon, Jean Harb,  Doina Precup<br>
              Neural Information Processing Systems (NIPS) Hierarchichal Reinforcement Learning Workshop, 2017
              </p>


            <div class="paper" id="ppoc">
            <a href="https://arxiv.org/pdf/1712.00004.pdf">pdf</a> |
            <a href="./data/options_continuousactions.bib">bibtex</a> |
            <a href="https://github.com/mklissa/PPOC">code</a>

            </div>
            </td>
          </tr>


        </table>







        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="justify" border="0" cellspacing="15" cellpadding="10">


          <tr>
            <td width="15%" valign="center" align="center"><img src="images/mcgill.png" alt="mcgill" width="60" height="82"></td>
            <td width="85%" valign="center">
              <p>
                <span><strong>McGill University</strong></span><span style="float:right">2020 - Present</span>
                <br>
                PhD in Computer Science
                <br>
                Supervisor: <a href="https://www.cs.mcgill.ca/~dprecup/"> Prof. Doina Precup</a>
                <br>
              </p>
            </td>
          </tr>


          <tr>
            <td width="15%" valign="center" align="center"><img src="images/mcgill.png" alt="mcgill" width="60" height="82"></td>
            <td width="85%" valign="center">
              <p>
                <span><strong>McGill University</strong></span><span style="float:right">2018 - 2020</span>
                <br>
                MSc in Computer Science
                <br>
                Supervisor: <a href="https://www.cs.mcgill.ca/~dprecup/"> Prof. Doina Precup</a>
                <br>
              </p>
            </td>
          </tr>

          <tr>
            <td width="15%" valign="center" align="center"><img src="images/poly_logo.jpeg" alt="poly" width="80" height="80"></td>
            <td width="85%" valign="center">
              <p>
                <span><strong>Polytechnique Montréal</strong></span><span style="float:right">2014 - 2018</span>
                <br>
                BEng in Electrical Engineering
                <br>
                Supervisor: <a href="https://www.calozc.org/"> Prof. Christophe Caloz</a>
              </p>
            </td>
          </tr>
        </table>



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Reviewing</heading>
    </td>
  </tr>
</tbody></table>

<table width="100%" align="center" border="0" cellpadding="0">
  <tr><td>
    <ul>
     <li> NeurIPS: 2020 / 2021</li>
    <li> ICML: 2021</li>
    <li> AAAI: 2021 / 2022</li>
    <li> ICLR: 2022 </li>
    </ul>
  </td></tr>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Selected Awards</heading>
    </td>
  </tr>
</tbody></table>

<table width="100%" align="center" border="0" cellpadding="0">
  <tr><td>
    <ul>
     <li> Natural Sciences and Engineering Research Council of Canada (NSERC)  Alexander Graham Bell Canada Graduate Scholarship (2020-2023)</li>
    <li> Fonds de Recherche du Québec - Nature et Technologie (FRQNT)  Masters Research Scholarship (2018-2020)</li>
    <li> McGill Graduate Excellence Award (2018-2020)</li>
    <li> Ordre des Ingénieurs Foundation Excellence Scholarship (2016)</li>
    </ul>
  </td></tr>
</table>



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                A special thanks to this <a href="https://jonbarron.info/">template</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>









</body>

</html>
